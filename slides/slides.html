<!DOCTYPE html>
<html>
<head>
<title></title>
<!-- 2017-10-19 Thu 00:24 -->
<meta  charset="utf-8" />
<meta  htto-equiv="X-UA-Compatible" content="chrome=1" />
<meta  name="generator" content="Org-mode with org-ioslide" />
<meta  name="author" content="Raynold Ng" />


<!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
<!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--This one seems to work all the time, but really small on ipad-->
<!--<meta name="viewport" content="initial-scale=0.4">-->
<meta name="apple-mobile-web-app-capable" content="yes" />
<link rel="stylesheet" media="all" href="theme/css/default.css" />
<link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css" />
<link rel="stylesheet" media="all" href="theme/css/small-icon.css" />
<base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
<script data-main="js/slides" src="js/require-1.0.8.min.js"></script>

   <script src="js/jquery-1.7.1.min.js" type="text/javascript"></script>

<script src="js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML,local/local" type="text/javascript"></script>
</head>
<body style="opacity: 0">
<slides class="layout-widescreen">
<slide class="title-slide segue nobackground">
       <aside class="gdbar"><img src="images/tensorflow.png"></aside>
       <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
       <hgroup class="auto-fadein">
         <h1 data-config-title><!-- populated from slide_config.json --></h1>
         <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
         <p data-config-presenter><!-- populated from slide_config.json --></p>
       </hgroup>
    </slide>
  <slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org90424dd" class="outline-2">
<h2 id="org90424dd">Agenda</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Installation and Setup</li>
<li>What's TensorFlow?</li>
<li>Machine Learning Primer</li>
<li>Basic TensorFlow concepts</li>
<li>MNIST Example
<ul>
<li>Softmax</li>
<li>Convoluted Neural Networks</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org8341ab2" class="outline-2">
<h2 id="org8341ab2">Installation and Setup</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Ensure that you have the following installed:
</p>
<ol>
<li>TensorFlow: <a href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a></li>
<li>Python 3: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
<li>Jupyter (recommended): <a href="http://jupyter.org/">http://jupyter.org/</a></li>
</ol>

<p>
Materials are available here: insert link
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgbac62b8" class="outline-2">
<h2 id="orgbac62b8">Machine Learning Primer</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Meant to provide basic mathematical background. 
</p>


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org277e88c" class="outline-3">
<h3 id="org277e88c">Structure in data</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>some interpretations to "structure in data"
<ul>
<li>given some data, one can predict other data points with some confidence</li>
<li>one can compress the data, i.e., store the smae amount of information, with
less space</li>
</ul></li>
</ul>

\begin{align*}
A = {1, 2, 6, 4, 7, 9, 0} \\
B = {1, 2, 1, 2, 1, 2, 1}
\end{align*}

<ul>
<li>we might say that A has apparent structure while B does not</li>
</ul>


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7042aa0" class="outline-4">
<h4 id="org7042aa0">Entropy</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>quantified as Entropy of Process</li>
</ul>
<p>
\[H(X) = -\sum_{i=1}^{N} p(x_i) \log_2 p(x_i)\]
</p>
<ul>
<li>If entropy increases, uncertainty in prediction increases</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org9cbdc9e" class="outline-4">
<h4 id="org9cbdc9e">Entropy (examples)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Example: fair dice</li>
</ul>
<p>
\[H(\text{fair dice roll}) = -\sum_{i=1}^6 \frac{1}{6} \log_2 \frac{1}{6}=2.58\]
</p>
<ul>
<li>Example: biased 20:80 coin</li>
</ul>
<p>
\[H(20/80 \text{ coin toss}) = -\frac{1}{5}\log_2 \frac{1}{5}-\frac{4}{5}\log_2 \frac{4}{5} = 0.72\]
</p>
<ul>
<li>biased coin toss has lower entropy; predicting its outcome is easier than a fair dice</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge6d5604" class="outline-4">
<h4 id="orge6d5604">Information in features</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>to make predicts, signals need to be information rich</li>
<li>[insert image on clusters here]</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc4bf11f" class="outline-4">
<h4 id="orgc4bf11f">Dimensionality Reduction</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>signals used to make predictions can contain redundant information</li>
<li>true dimensionality of a problem is often much smaller than number of
available features</li>
<li>common method for dimensionality reduction: PCA</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org9cf5169" class="outline-3">
<h3 id="org9cf5169">Basic Concepts for TensorFlow</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Recall from linear algebra that:
</p>
<ul>
<li>Scalar: an array in 0-D</li>
<li>Vector: an array in 1-D</li>
<li>Matrix: an array in 2-D</li>
</ul>

<p>
All are <b>tensors</b> of n-order. Similary, tensors can be transformed with
operations. Simple linear regression model:
</p>

<p>
\[w_o + w_1 x = \hat{y}\]
</p>

<p>
\(w_0\) and \(w_1\) are <b>weights</b>, that are determined during training. \(\hat{y}\) is
predicted outcome
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc7b4b59" class="outline-3">
<h3 id="orgc7b4b59">Graph Representation of ML Models</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Can represent linear regression as a graph
</p>


<div class="figure">
<p><img src="images/linear_reg_graph.png" alt="linear_reg_graph.png" width="40%" />
</p>
</div>

<ul>
<li>operations are represented as nodes</li>
<li>graph shows how data is transformed by nodes and what is passed between them</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc0a27d6" class="outline-3">
<h3 id="orgc0a27d6">Graph Representation of ML Models (1)</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Consider a slightly larger neural net graph:
</p>

<div class="figure">
<p><img src="images/neural_net.png" alt="neural_net.png" width="60%" />
</p>
</div>

<p>
For more complex models, it could be helpful to visualize your graph.
<a href="https://www.tensorflow.org/versions/r0.7/how_tos/graph_viz/index.html">TensorBoard</a> provides this virtualization tool
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org86ce921" class="outline-3">
<h3 id="org86ce921">Activation Functions</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>If \(g(u)\) is linear, then we return to linear regression</li>
<li>In practice, \(g(\dots)\) is non-linear, and a popular function is the rectified linear unit (<b>ReLU</b>):</li>
</ul>
<p>
\[g(u) = max(0, u)\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/relu.png" alt="relu.png" width="70%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org745c0ce" class="outline-3">
<h3 id="org745c0ce">Model Output</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>output depends on activation function used, but is generally any real number \([-\infty, \infty]\)</li>
<li>For categorical classification, e.g. binary classification, an additional
sigmoid function can be applied to bring the output to range of \([0,1]\)</li>
</ul>
<p>
\[S(x) = \frac{1}{1+e^{-x}}\]
[insert image]
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc75e0e0" class="outline-3">
<h3 id="orgc75e0e0">Softmax Function</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>for multi-class prediction (e.g. image classification) a softmax function is used:</li>
</ul>
<p>
\[S_j(\boldsymbol{z}) = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} \text{ for }j=1,\dots,k\]
</p>
<ul>
<li>squash \(K\) dimensional vector <b>z</b> to a \(K\) dimensional vector that sum to 1</li>
</ul>
<p>
\[\sum_{j=1}^k S_j(\boldsymbol{z}) = 1\]
</p>
<ul>
<li>state usually represented with <b>one-hot encoding</b>, e.g for dice roll \((0,0,1,0,0,0)\)</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgf56253f" class="outline-2">
<h2 id="orgf56253f">Basic TensorFlow Concepts</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org9a568f2" class="outline-3">
<h3 id="org9a568f2">Data Flow Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Tensorflow separates definition of computations from their execution
</p>

<p>
Phases:
</p>
<ol>
<li>assemble the graph</li>
<li>use a <code>session</code> to execute operations in the graph</li>
</ol>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
a = tf.add(3,5)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd4ac24f" class="outline-3">
<h3 id="orgd4ac24f">Visualizing with TensorBoard</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>`tf.summary.FileWriter` serializes the graph into a format the TensorBoard can read</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
tf.summary.FileWriter("logs", tf.get_default_graph()).close()</pre>

</div>

<ul>
<li>in the same directory, run:</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="sh">
tensorboard --logdir=logs</pre>

</div>

<ul>
<li>This will launch an instance of TensorBoard that you can access at <a href="http://localhost:6006">http://localhost:6006</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc2d4c17" class="outline-3">
<h3 id="orgc2d4c17">How to get value of `a`?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
print(a)</pre>

</div>

<p>
Create a `session`, and within it, evaluate the graph
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
print(sess.run(a))
sess.close()</pre>

</div>

<p>
Alternatively:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
with tf.Session() as sess:
    print(sess.run(a))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgba71df1" class="outline-3">
<h3 id="orgba71df1">Practice with More Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Try to generate the following graph:
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/graph2.png" alt="graph2.png" width="70%" />
</p>
</div>
</article>

<p>
Useful functions: <code>tf.add</code>, <code>tf.multiply</code>, <code>tf.pow</code>
</p>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7e09200" class="outline-3">
<h3 id="org7e09200">Solution</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = 2
y = 3
op1 = tf.add(x, y)
op2 = tf.multiply(x, y)
op3 = tf.pow(op1, op2)
with tf.Session() as sess:
    op3 = sess.run(op3)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb2f1a10" class="outline-3">
<h3 id="orgb2f1a10">TensorFlow Variables</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>TensorFlow variables used to represent shared, persistant state manipulated by your program</li>
<li>variables hold and update parameters in your model during training</li>
<li>variables contain tensors</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W1 = tf.ones((2,2))
W2 = tf.Variable(tf.zeros((2,2)), name="weights")

with tf.Session() as sess:
    print(sess.run(W1))
    sess.run(tf.global_variables_initializer())
    print(sess.run(W2))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgf25dc46" class="outline-3">
<h3 id="orgf25dc46">Updating Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <code>tf.assign</code> to assign a value to a variable
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
state = tf.Variable(0, name="counter")
new_value = tf.add(state, tf.constant(1))
update = tf.assign(state, new_value)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(state))
    for _ in range(3):
        sess.run(update)
        print(sess.run(state))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org09e7174" class="outline-3">
<h3 id="org09e7174">Fetching Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.constant(3.0)
input2 = tf.constant(2.0)
input3 = tf.constant(5.0)
intermed = tf.add(input2, input3)
mul = tf.multiply(input1, intermed)

with tf.Session() as sess:
    result = sess.run([mul, intermed])
    print(result)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org15e78ed" class="outline-3">
<h3 id="org15e78ed">TensorFlow Placeholders</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.placeholder</code> variables represent our input data</li>
<li><code>feed_dict</code> is a python dictionary that maps <code>tf.placeholder</code> variables to data</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)

output = tf.multiply(input1, input2)

with tf.Session() as sess:
    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org39bc5be" class="outline-3">
<h3 id="org39bc5be">Example: Linear Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgff5cafe" class="outline-4">
<h4 id="orgff5cafe">Recap</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>we have two weights \(w_0\) and \(w_1\), we want the model to figure out good weights by minimizing prediction error</li>
<li>define the following <b>loss function</b></li>
</ul>

<p>
\[L = \sum (y - \hat{y})^2\]
</p>

<p>
Supose we want to model the following "unknown" function:
</p>

<p>
\[y = x + 20 \sin(x/10)\]
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga3d08a0" class="outline-4">
<h4 id="orga3d08a0">Plot Input Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Make sure that <code>seaborn</code> and <code>matplotlib</code> are installed. If you are using Jupyter, add <code>%matplotlib inline</code> in the code cell.
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
import numpy as np
import seaborn
import matplotlib.pyplot as plt
%matplotlib inline
# Define input data
X_data = np.arange(100, step=.1)
y_data = X_data + 20 * np.sin(X_data/10)
# Plot input data
plt.scatter(X_data, y_data)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org70642fe" class="outline-4">
<h4 id="org70642fe">Scatter Plot</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sample_data.png" alt="sample_data.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgbfebe4f" class="outline-4">
<h4 id="orgbfebe4f">Define Variables and Placeholders</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define data size and batch size
n_samples = 1000
batch_size = 100

# TensorFlow is particular about shapes, so resize
X_data = np.reshape(X_data, (n_samples, 1))
y_data = np.reshape(y_data, (n_samples, 1))

# Define placeholders for input
X = tf.placeholder(tf.float32, shape=(batch_size, 1))
y = tf.placeholder(tf.float32, shape=(batch_size, 1))</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3d950ce" class="outline-4">
<h4 id="org3d950ce">Loss Function</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Loss function is defined as:
\[J(W,b) = \frac{1}{N}\sum_{i=1}^{N}(y_i-(W_{x_i}+b))^2\]
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define variables to be learned
with tf.variable_scope("linear-regression"):
    W = tf.get_variable("weights", (1,1),
                        initializer = tf.random_normal_initializer())
    b = tf.get_variable("bias", (1,),
                        initializer = tf.constant_initializer(0.0))
    y_pred = tf.matmul(X, W) + b
    loss = tf.reduce_sum((y - y_pred)**2/n_samples)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org80ce0c4" class="outline-4">
<h4 id="org80ce0c4">Define Optimizer and Train Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="smaller" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define optimizer operation
opt_operation = tf.train.AdamOptimizer().minimize(loss)
with tf.Session() as sess:
    # Initialize all variables in graph
    sess.run(tf.global_variables_initializer())
    # Gradient descent for 500 steps:
    for _ in range(500):
        # Select from random mini batch
        indices = np.random.choice(n_samples, batch_size)
        X_batch, y_batch = X_data[indices], y_data[indices]
        # Do gradient descent step
        _, loss_val = sess.run([opt_operation, loss], feed_dict={X: X_batch, y: y_batch})
    print(sess.run([W, b]))
    # Display results
    plt.scatter(X_data, y_data)
    plt.scatter(X_data, sess.run(W) * X_data + sess.run(b), c='g')
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgae3474d" class="outline-4">
<h4 id="orgae3474d">Results</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/trained_model.png" alt="trained_model.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org6239f5e" class="outline-2">
<h2 id="org6239f5e">MNIST and TensorFlow</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1a69baf" class="outline-3">
<h3 id="org1a69baf">Introduction</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>MNIST is the hello world of machine learning</li>
<li>Simple computer vision dataset, consists of images of handwritten digits</li>
<li>We are going to train a model to predict what the digits are</li>
</ul>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/MNIST.png" alt="MNIST.png" width="80%" />
</p>
</div>
</article>


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org17a317b" class="outline-4">
<h4 id="org17a317b">Importing MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
To download and read in the data automatically:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)</pre>

</div>

<p>
One hot encoding
</p>
<ul>
<li>labels have been converted to a vector of length equal to number of classes.</li>
<li>the ith element is 1, rest are 0. E.g. Digit 1: \([0,1,\dots]\)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org51ac5f8" class="outline-4">
<h4 id="org51ac5f8">MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
The MNIST data is split into three parts:
</p>
<ol>
<li>55,000 data points of training data (`mnist.train`)</li>
<li>10,000 data points of test data (`mnist.test`)</li>
<li>5,000 data points of validation data (`mnist.validation`)</li>
</ol>

<p>
Every MNIST data has 2 parts:
</p>
<ol>
<li>an image of a handwritten digit (call it "x")</li>
<li>corresponding label (call it "y")</li>
</ol>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org40637d8" class="outline-3">
<h3 id="org40637d8">Softmax Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0feb3ec" class="outline-4">
<h4 id="org0feb3ec">Overview</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_1.png" alt="softmax_1.png" width="140%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org03a6f45" class="outline-4">
<h4 id="org03a6f45">Overview (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_2.png" alt="softmax_2.png" width="120%" />
</p>
</div>
</article>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_3.png" alt="softmax_3.png" width="120%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb2b76ca" class="outline-4">
<h4 id="orgb2b76ca">Defining Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>multiply 784-dimensional vectors by \(W\) to produce 10-dimensional vectors of evidence</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))

y = tf.nn.softmax(tf.matmul(x, W) + b)</pre>

</div>
<ul>
<li>multiply <code>x</code> with <code>W</code> in that order as <code>x</code> has shape <code>[None, 784]</code> and <code>W</code> has shape <code>[784, 10]</code></li>
<li>Small trick to deal with <code>x</code> being a 2D tensor with multiple inputs.</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga1afd9d" class="outline-4">
<h4 id="orga1afd9d">Training</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <b>cross-entropy</b> to determine loss of model:
\[H_{y'}=-\sum_{i} y_i' \log(y_i)\]
</p>

<p>
Where:
</p>
<ul>
<li>\(y\) is our predicted probability distribution</li>
<li>\(y'\) is the true distribution (one-hot vector with digit labels)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org5f8263b" class="outline-4">
<h4 id="org5f8263b">Training (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Need a placeholder to implement cross entropy:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), 
                                              reduction_indices = [1]))</pre>

</div>

<p>
<code>tf.reduce_sum</code> computes the sum of elements across dimensions of a tensor
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# 'x' is [[1, 1, 1]
#         [1, 1, 1]]
tf.reduce_sum(x) ==&gt; 6
tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]
tf.reduce_sum(x, 1) ==&gt; [3, 3]</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga3818eb" class="outline-4">
<h4 id="orga3818eb">Training (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
for _ in range(400):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})</pre>

</div>

<p>
Using small batches of random data is called <b>stochastic training</b>, it is more
feasible than training on the entire data set
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1e84805" class="outline-4">
<h4 id="org1e84805">Evaluating Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.argmax</code> is an extrememly helpful function that returns the index of the highest entry in a tensor along some axis.</li>
<li><code>tf.argmax(y,1)</code> is predicted label while `tf.argmax(y_, 1)` is the actual label</li>
<li><code>tf.equal</code> to check if prediction matches the true</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))</pre>

</div>

<p>
Approx 91% is very bad, 6 digit ZIP code would have an accuracy rate of 57% 
</p>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org4834179" class="outline-3">
<h3 id="org4834179">Convolutional Neural Network</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge076485" class="outline-4">
<h4 id="orge076485">Introduction</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolutional Networks work by moving smaller filter across the input image</li>
<li>Filters are re-used for recognizing patters throughout the entire input image</li>
<li>This makes Convolutional Networks much more powerfule than Fully-Connected
networks with the same number of variables</li>
<li>Convolutional Networks are also faster to train</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdc2c612" class="outline-4">
<h4 id="orgdc2c612">Flowchart</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/cnn_network_flowchart.png" alt="cnn_network_flowchart.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc85eaa8" class="outline-4">
<h4 id="orgc85eaa8">Features</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features.png" alt="features.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org02cf733" class="outline-4">
<h4 id="org02cf733">Features (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features_2.png" alt="features_2.png" width="60%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org634a9c4" class="outline-4">
<h4 id="org634a9c4">Convolution</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution.png" alt="convolution.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6303465" class="outline-4">
<h4 id="org6303465">Convolution (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_2.png" alt="convolution_2.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgab7e369" class="outline-4">
<h4 id="orgab7e369">Convolution (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_3.png" alt="convolution_3.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3230c34" class="outline-4">
<h4 id="org3230c34">Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling.png" alt="pooling.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6f11a85" class="outline-4">
<h4 id="org6f11a85">Pooling (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling_2.png" alt="pooling_2.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdea5de0" class="outline-4">
<h4 id="orgdea5de0">Fully Connected Layers</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/layers.png" alt="layers.png" width="90%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdafa3a3" class="outline-4">
<h4 id="orgdafa3a3">Hyper Parameters</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolution:
<ul>
<li>Number of features</li>
<li>Size of features</li>
</ul></li>
<li>Pooling
<ul>
<li>Window size</li>
<li>Window stride</li>
</ul></li>
<li>Fully Connected
<ul>
<li>number of neurons</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3d58a78" class="outline-4">
<h4 id="org3d58a78">Weight Initialization</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Helper functions to create ReLU neurons
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org2d9ed09" class="outline-4">
<h4 id="org2d9ed09">Convolution and Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga298118" class="outline-4">
<h4 id="orga298118">First Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>first layer consists of convolution and then max pooling</li>
<li>compute 32 fearures for each 5x5 patch</li>
<li>also define our bias</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
x_image = tf.reshape(x, [-1, 28, 28, 1]) # ?, width, height, number of color channels
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1) # reduce image to 14x14</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4a815b2" class="outline-4">
<h4 id="org4a815b2">Second Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>64 features for each 5x5 patch</li>
<li>image is now 7x7</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga401cb2" class="outline-4">
<h4 id="orga401cb2">Densely Connected Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>add a fully connected layer with 1024 neurons to allow processing of the entire image</li>
<li>reshape tensor from pooling layer into batch of vectors, muplity by a weight matrix, add a bias and then apply ReLU</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc1daac0" class="outline-4">
<h4 id="orgc1daac0">Read Out Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Add one last layer, similar to softmax regression
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdb7c60f" class="outline-4">
<h4 id="orgdb7c60f">Train and Evaluate the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
cross_entropy = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org433ab2c" class="outline-4">
<h4 id="org433ab2c">Train and Evaluate the Model (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
sess.run(tf.global_variables_initializer())
with sess.as_default():
    for i in range(500):
        batch = mnist.train.next_batch(50)
    if i % 100 == 0:
        train_accuracy = accuracy.eval(feed_dict={
          x: batch[0], y_: batch[1]})
        print('step %d, training accuracy %g' % (i, train_accuracy))
        train_step.run(feed_dict={x: batch[0], y_: batch[1]})

    print('test accuracy %g' % accuracy.eval(feed_dict={
      x: mnist.test.images, y_: mnist.test.labels}))</pre>

</div>


</article>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orge0452f4" class="outline-3">
<h3 id="orge0452f4">Saving and Restoring your model</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org29e7aab" class="outline-4">
<h4 id="org29e7aab">Exporting the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>We can export the model for use in our own applications</li>
<li>use <code>tf.train.Saver</code> to save the graph and the trained weights</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
model_path = "./tmp/model.ckpt"
save_path = saver.save(sess, model_path) # saver is not declared???
print("Model saved in file: %s" % save_path)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0a4221c" class="outline-4">
<h4 id="org0a4221c">Restoring the Session</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
saver = tf.train.Saver()
model_path = "./tmp/model.ckpt"
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  saver.restore(sess, model_path)
  print("Accuracy:", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))</pre>

</div>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1720b32" class="outline-3">
<h3 id="org1720b32">Toy Program</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
[insert link to github repo here]
</p>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" thank-you-slide segue nobackground" style="background-image: url(nil)">
<aside class="gdbar right"><img src="images/tensorflow.png"></aside><article class="flexbox vleft auto-fadein" id="text-">
<h2>
  <p>Thank You</p>
</h2>
<br>
<p class="auto-fadein" data-config-contact>
</p>
</article>

</slide>
<slide class="backdrop"></slide>
</slides> 
<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body> 

</html>
